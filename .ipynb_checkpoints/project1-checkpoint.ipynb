{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee67aa71",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black\">\n",
    "<b><center><font size=\"4\">Ciência de Dados em Larga Escala</font></center></b>\n",
    "\n",
    "<b><center><font size=\"3\">Project 1</font></center></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698cbe58",
   "metadata": {},
   "source": [
    "**Notebook Developed by**: Rafael Antunes Lourenço<br>\n",
    "**Número:** 48115 <br>\n",
    "**Email:**  rafael.a.lourenco@ubi.pt<br>\n",
    "<hr>\n",
    "\n",
    "<p><a href=\"project1.ipynb\" title=\"Download Notebook\" download><img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/download.jpg\" align = \"left\" width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e672d",
   "metadata": {},
   "source": [
    "### Introdução (Coleta e Indexação de Dados de Criptomoeda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe88ff",
   "metadata": {},
   "source": [
    "Este trabalho visa coletar e armazenar dados atualizados sobre criptomoedas, utilizando a API do CoinMarketCap e o Elasticsearch.\n",
    "\n",
    "-Configuração Inicial:\n",
    "\n",
    "Inicialmente, são definidas as configurações necessárias, como as credenciais de acesso à API do CoinMarketCap e os parâmetros para a solicitação dos dados. Além disso, é estabelecida a estrutura básica para a indexação dos dados no Elasticsearch, incluindo a definição de um arquivo de log para registrar as operações realizadas.\n",
    "\n",
    "-Coleta e Atualização de Dados:\n",
    "\n",
    "O processo de coleta é realizado periodicamente, a cada hora, durante um período de cinco dias. Para cada iteração do loop principal, são feitas solicitações à API do CoinMarketCap para obter os dados mais recentes sobre criptomoedas. Os dados obtidos são então processados e adicionados a um arquivo JSON local, juntamente com um registro de timestamp para acompanhar a evolução temporal das informações.\n",
    "\n",
    "-Gerenciamento de Erros e Logs:\n",
    "\n",
    "O código implementa tratamento de exceções para lidar com possíveis falhas durante a coleta e atualização dos dados. O registro de logs fornece uma visão detalhada das operações realizadas, incluindo mensagens de erro e informações sobre a execução do script.\n",
    "\n",
    "-Objetivos Futuros:\n",
    "\n",
    "O próximo passo após a coleta e armazenamento dos dados é a análise e visualização dos mesmos, utilizando ferramentas como o Kibana. A análise dos dados permitirá a identificação de tendências e padrões no mercado de criptomoedas, auxiliando na tomada de decisões e no desenvolvimento de estratégias de investimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71168e",
   "metadata": {},
   "source": [
    "### Importações e Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c658497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee33a2",
   "metadata": {},
   "source": [
    "Nesta parte, estamos importando os módulos necessários para fazer requisições HTTP (requests), lidar com exceções de requisição (RequestException), manipular JSON (json), trabalhar com tempo (time e datetime), e registrar logs (logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82af911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o logger\n",
    "logging.basicConfig(filename='app.log', filemode='a', format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0963c91",
   "metadata": {},
   "source": [
    "Aqui, estamos configurando o logger para registrar eventos em um arquivo de log chamado 'app.log'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ffaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração inicial\n",
    "headers = {\n",
    "    'Accepts': 'application/json',\n",
    "    'X-CMC_PRO_API_KEY': '7e4ad96d-e64a-4a03-8c54-8d0040f42b39'\n",
    "}\n",
    "params = {\n",
    "    'start': '1',\n",
    "    'limit': '2',\n",
    "    'convert': 'EUR'\n",
    "}\n",
    "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c280b8a",
   "metadata": {},
   "source": [
    "Essas linhas definem os cabeçalhos da requisição, os parâmetros da URL e a URL base para acessar a API do CoinMarketCap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97490ccf",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para adicionar dados ao JSON\n",
    "def adicionar_dados_ao_json(novos_dados, nome_do_ficheiro):\n",
    "    try:\n",
    "        # Ler o ficheiro JSON existente\n",
    "        with open(nome_do_ficheiro, 'r') as file:\n",
    "            dados_existentes = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # Se o ficheiro não existir, criar um dicionário vazio\n",
    "        dados_existentes = {}\n",
    "\n",
    "    # Adicionar a marca de tempo aos novos dados\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for symbol, data in novos_dados.items():\n",
    "        # Se a chave não existir, criar uma lista para os registros\n",
    "        if symbol not in dados_existentes:\n",
    "            dados_existentes[symbol] = []\n",
    "        # Verificar se o valor associado à chave é uma lista\n",
    "        elif not isinstance(dados_existentes[symbol], list):\n",
    "            # Se não for uma lista, criar uma lista com o valor existente\n",
    "            dados_existentes[symbol] = [dados_existentes[symbol]]\n",
    "        # Adicionar os novos dados com a marca de tempo à lista do ativo\n",
    "        dados_existentes[symbol].append({'timestamp': timestamp, 'valor': data['price'], 'volume_24h': data['volume_24h'], 'volume_change_24h': data['volume_change_24h'], 'market_cap': data['market_cap']})\n",
    "\n",
    "    # Escrever os dados atualizados no ficheiro\n",
    "    with open(nome_do_ficheiro, 'w') as file:\n",
    "        json.dump(dados_existentes, file, indent=4)\n",
    "\n",
    "    # Log do processo de adição de dados\n",
    "    logging.info(f\"Dados adicionados ao arquivo {nome_do_ficheiro}: {novos_dados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb91e56",
   "metadata": {},
   "source": [
    "Essa função adicionar_dados_ao_json recebe novos dados e um nome de arquivo. Ela lê o arquivo JSON existente, adiciona os novos dados com timestamps e escreve-os de volta no arquivo. Também registra a adição de dados no arquivo de log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2cdf44",
   "metadata": {},
   "source": [
    "### Cálculo do Tempo Total para o Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ab252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o tempo total para o loop (5 dias)\n",
    "tempo_total = 3600 * 24 * 5\n",
    "tempo_inicio = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad064d8",
   "metadata": {},
   "source": [
    "Nesta parte, calculamos o tempo total de execução do loop em 5 dias. Convertendo 5 dias em segundos, multiplicamos o número de segundos em uma hora (3600), pelo número de horas em um dia (24), e depois multiplicamos pelo número de dias (5).\n",
    "Na segunda linha, registramos o tempo atual no início do loop, usando a função time.time(). Esse valor é usado posteriormente para calcular o tempo decorrido durante a execução do loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6040b9c",
   "metadata": {},
   "source": [
    "### Loop Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop principal\n",
    "tempo_inicio = time.time()\n",
    "while time.time() - tempo_inicio < tempo_total:\n",
    "    try:\n",
    "        # Calcular o tempo restante até a próxima hora\n",
    "        tempo_atual = datetime.now()\n",
    "        proxima_hora = tempo_atual + timedelta(hours=1)\n",
    "        proximo_inicio = proxima_hora.replace(minute=0, second=0, microsecond=0)\n",
    "        tempo_restante = (proximo_inicio - tempo_atual).total_seconds()\n",
    "\n",
    "        # Fazer o pedido à API\n",
    "        r = requests.get(url, params=params, headers=headers)\n",
    "        r.raise_for_status()  # Lança uma exceção se o status da resposta não for 200 OK\n",
    "        coins = r.json()['data']\n",
    "\n",
    "        # Preparar os dados para adicionar\n",
    "        dados_para_adicionar = {}\n",
    "        for coin in coins:\n",
    "            symbol = coin['symbol']\n",
    "            quote = coin.get('quote', {}).get('EUR', {})  # Ajuste para acessar 'quote' de forma segura\n",
    "            dados_para_adicionar[symbol] = {\n",
    "                'price': quote.get('price', 0),\n",
    "                'volume_24h': quote.get('volume_24h', 0),\n",
    "                'volume_change_24h': quote.get('volume_change_24h', 0),\n",
    "                'market_cap': quote.get('market_cap', 0)\n",
    "            }\n",
    "\n",
    "        # Adicionar os dados ao ficheiro JSON\n",
    "        adicionar_dados_ao_json(dados_para_adicionar, 'valores_coins.json')\n",
    "\n",
    "        # Aguardar até a próxima hora\n",
    "        time.sleep(tempo_restante)\n",
    "\n",
    "    except RequestException as e:\n",
    "        # Log de erros\n",
    "        logging.error(f\"Erro durante a solicitação: {e.__class__.__name__} - {e}\")\n",
    "\n",
    "        # Aguardar um tempo antes de tentar novamente\n",
    "        time.sleep(60)  # Aguarda 1 minuto antes de tentar novamente\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log de erros inesperados\n",
    "        logging.error(f\"Erro inesperado: {e.__class__.__name__} - {e}\")\n",
    "\n",
    "logging.info(\"A execução do script foi concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdf06f",
   "metadata": {},
   "source": [
    " Em seguida, o loop executa enquanto o tempo atual menos o tempo de início for menor que o tempo total. Dentro do loop, estamos a fazer uma solicitação à API do CoinMarketCap, preparando os dados para adicionar ao arquivo JSON e esperando até a próxima hora. Se ocorrer uma exceção durante a solicitação, ela será tratada e registrada no log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f2f52",
   "metadata": {},
   "source": [
    "### Carregar o Arquivo JSON em Memória e Imprimir Registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o ficheiro JSON em memória\n",
    "with open('valores_coins.json', 'r') as file:\n",
    "    dados = json.load(file)\n",
    "\n",
    "# Percorrer e imprimir os conteúdos de 5 dos registros\n",
    "for symbol, registros in dados.items():\n",
    "    print(f\"Ativo: {symbol}\")\n",
    "    for registro in registros[:5]:  # Apenas os primeiros 5 registros\n",
    "        timestamp = registro.get('timestamp', 'N/A')  # Obtém o timestamp ou 'N/A' se não existir\n",
    "        valor = registro.get('valor', 'N/A')  # Obtém o valor ou 'N/A' se não existir\n",
    "        volume_24h = registro.get('volume_24h', 'N/A')  # Obtém o volume_24h ou 'N/A' se não existir\n",
    "        volume_change_24h = registro.get('volume_change_24h', 'N/A')  # Obtém o volume_change_24h ou 'N/A' se não existir\n",
    "        market_cap = registro.get('market_cap', 'N/A')  # Obtém o market_cap ou 'N/A' se não existir\n",
    "        \n",
    "        print(f\"Timestamp: {timestamp}, Valor: {valor}, Volume 24h: {volume_24h}, Volume Change 24h: {volume_change_24h}, Market Cap: {market_cap}\")\n",
    "    print(\"\\n\")  # Adiciona uma linha em branco entre cada ativo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2271727",
   "metadata": {},
   "source": [
    "Nesta parte do código, estamos a carregar o arquivo JSON 'valores_coins.json' em memória e percorremos o seu conteúdos. Para cada ativo, imprimimos os detalhes dos primeiros 5 registros, incluindo timestamp, valor, volume 24h, mudança de volume em 24h e market cap. \n",
    "Se um campo não estiver presente em um registro, é impresso \"N/A\". \n",
    "Após imprimir os registros de um ativo, adicionamos uma linha em branco para separar os registros de ativos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b431e0",
   "metadata": {},
   "source": [
    "### Indexação dos Dados no Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Conectar ao Elasticsearch\n",
    "es = Elasticsearch()\n",
    "\n",
    "# Função para indexar dados no Elasticsearch\n",
    "def indexar_dados_no_elasticsearch(dados, indice):\n",
    "    for symbol, registros in dados.items():\n",
    "        for registro in registros:\n",
    "            # Indexar cada registro no Elasticsearch\n",
    "            es.index(index=indice, body=registro)\n",
    "\n",
    "# Carregar o ficheiro JSON em memória\n",
    "def carregar_dados_do_json(nome_do_ficheiro):\n",
    "    try:\n",
    "        # Ler o ficheiro JSON existente\n",
    "        with open(nome_do_ficheiro, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # Se o ficheiro não existir, retornar None\n",
    "        return None\n",
    "\n",
    "# Carregar os dados coletados do arquivo JSON\n",
    "dados = carregar_dados_do_json('valores_coins.json')\n",
    "\n",
    "# Indexar os dados no Elasticsearch\n",
    "if dados:\n",
    "    indexar_dados_no_elasticsearch(dados, 'valores_coins')\n",
    "\n",
    "print(\"Indexação concluída com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55f396",
   "metadata": {},
   "source": [
    "Nesta parte, estamos a adaptar o código para carregar os dados coletados do arquivo JSON 'valores_coins.json' em memória. Em seguida, definimos uma função 'indexar_dados_no_elasticsearch' para indexar os dados no Elasticsearch. Dentro dessa função, iteramos sobre os dados e indexamos cada registro no índice especificado.\n",
    "Se tudo correr bem, no final imprime uma mensagem, \"Indexação concluída com sucesso!\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea645a",
   "metadata": {},
   "source": [
    "### Recuperação de Informações no Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66789c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar o Elasticsearch e recuperar informações\n",
    "def consultar_elasticsearch(query, indice):\n",
    "    resultados = es.search(index=indice, body=query)\n",
    "    return resultados['hits']['hits']\n",
    "\n",
    "# Exemplo de queries para recuperação de informações\n",
    "queries = [\n",
    "    {\"query\": {\"match\": {\"symbol\": \"BTC\"}}},\n",
    "    {\"query\": {\"range\": {\"market_cap\": {\"gte\": 10000000000}}}}\n",
    "]\n",
    "\n",
    "# Executar as queries e imprimir resultados\n",
    "for query in queries:\n",
    "    resultados = consultar_elasticsearch(query, 'valores_coins')\n",
    "    print(\"Resultados para a query:\", query)\n",
    "    for hit in resultados:\n",
    "        print(\"Score:\", hit['_score'])\n",
    "        print(\"Registro:\", hit['_source'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beef27a",
   "metadata": {},
   "source": [
    "Nesta parte, definimos ma função 'consultar_elasticsearch' para consultar o Elasticsearch com uma determinada query e índice e devolver os resultados. De seguida, definimos algumas queries de exemplo e executamos usando a função 'consultar_elasticsearch'. Por fim, imprimimos os resultados das consultas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77afc7",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1ed2a",
   "metadata": {},
   "source": [
    "Neste trabalho, tive a oportunidade de explorar várias áreas da ciência de dados e desenvolvimento de software. Comecei por aprender a recolher dados através de uma API externa usando a biblioteca requests em Python. Durante este processo, aprendi a lidar com erros, implementando tratamentos adequados e registando eventos em logs para facilitar a depuração futura.\n",
    "\n",
    "Ao manipular os dados recebidos da API, explorei as nuances da manipulação de dados JSON em Python. Isso incluiu a leitura e escrita de ficheiros JSON, bem como a adição de novos dados aos registos existentes. Além disso, a familiarização com o trabalho com datas e tempo em Python permitiu-me agendar tarefas de recolha de dados de forma eficiente, garantindo que os registos fossem atualizados regularmente e marcados com timestamps precisos.\n",
    "\n",
    "No entanto, durante o desenvolvimento, enfrentei alguns problemas. Por exemplo, o programa parava sempre perto das 18h e não me aparecia nenhum erro nos logs. Isso exigiu uma investigação mais aprofundada, na qual perdi muito tempo, onde fiz cerca de 4 versões diferentes do meu Script mas todas elas com o mesmo problema, o que me levou a pensar que fosse alguma definição da máquina virtual \"PythonAnywhere\".\n",
    "\n",
    "Por fim, ao indexar os dados recolhidos no Elasticsearch, aprimorei as minhas habilidades em armazenamento e recuperação de informações em larga escala. Aprendi a realizar consultas eficientes para recuperar informações específicas com base em critérios definidos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
